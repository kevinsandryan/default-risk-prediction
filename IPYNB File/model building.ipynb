{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae61377",
   "metadata": {},
   "source": [
    "# Model Feature selection, hyperparameter tuning, and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889f4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e302e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('app_train.csv')\n",
    "app_test = pd.read_csv('app_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ad95d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 361)\n",
      "Testing shape:  (48744, 360)\n"
     ]
    }
   ],
   "source": [
    "print('Training shape: ', app_train.shape)\n",
    "print('Testing shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db0db5",
   "metadata": {},
   "source": [
    "## Remove collinear features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f87bb",
   "metadata": {},
   "source": [
    "collinear features merupakan feature yang sangat berkorelasi satu dengan yang lainnya. Adanya feature ini menyebabkan learning model menjadi overfit karena varians dari model meningkat, sehingga model akan sangat sensitif terhadap perubahan kecil.\n",
    "Saya set threshold pada nilai 0.9, jika terdapat nilai korelasi lebih dari 0.9, maka feature tersebut dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922ec470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH_x</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>STATUS_0_MEAN</th>\n",
       "      <th>STATUS_1_MEAN</th>\n",
       "      <th>STATUS_2_MEAN</th>\n",
       "      <th>STATUS_3_MEAN</th>\n",
       "      <th>STATUS_4_MEAN</th>\n",
       "      <th>STATUS_5_MEAN</th>\n",
       "      <th>STATUS_C_MEAN</th>\n",
       "      <th>STATUS_X_MEAN</th>\n",
       "      <th>STATUS_nan_MEAN</th>\n",
       "      <th>PREVIOUS_LOAN_COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011773</td>\n",
       "      <td>-0.009829</td>\n",
       "      <td>-0.010272</td>\n",
       "      <td>-0.012384</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>-0.009581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>-0.001850</td>\n",
       "      <td>-0.010326</td>\n",
       "      <td>-0.013329</td>\n",
       "      <td>-0.015889</td>\n",
       "      <td>-0.017766</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>-0.081345</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>-0.087053</td>\n",
       "      <td>-0.180259</td>\n",
       "      <td>0.739330</td>\n",
       "      <td>0.433684</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184563</td>\n",
       "      <td>0.197814</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>0.021650</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>-0.172132</td>\n",
       "      <td>-0.017152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339276</td>\n",
       "      <td>0.414387</td>\n",
       "      <td>0.348522</td>\n",
       "      <td>0.371289</td>\n",
       "      <td>0.081557</td>\n",
       "      <td>-0.025511</td>\n",
       "      <td>0.113180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>-0.034895</td>\n",
       "      <td>-0.047507</td>\n",
       "      <td>-0.047860</td>\n",
       "      <td>-0.027140</td>\n",
       "      <td>-0.033076</td>\n",
       "      <td>0.098954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928168</td>\n",
       "      <td>0.998997</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>-0.204316</td>\n",
       "      <td>-0.301116</td>\n",
       "      <td>-0.133019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188297</td>\n",
       "      <td>-0.201939</td>\n",
       "      <td>-0.062915</td>\n",
       "      <td>-0.068763</td>\n",
       "      <td>-0.066161</td>\n",
       "      <td>-0.041964</td>\n",
       "      <td>0.155460</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930591</td>\n",
       "      <td>0.381766</td>\n",
       "      <td>-0.081644</td>\n",
       "      <td>-0.206107</td>\n",
       "      <td>-0.027237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176470</td>\n",
       "      <td>-0.156915</td>\n",
       "      <td>-0.059184</td>\n",
       "      <td>-0.065268</td>\n",
       "      <td>-0.063570</td>\n",
       "      <td>-0.040668</td>\n",
       "      <td>0.146155</td>\n",
       "      <td>0.052523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "SK_ID_CURR               NaN     -0.011773         -0.009829   -0.010272   \n",
       "CNT_CHILDREN             NaN           NaN          0.066650   -0.081345   \n",
       "AMT_INCOME_TOTAL         NaN           NaN               NaN    0.339276   \n",
       "AMT_CREDIT               NaN           NaN               NaN         NaN   \n",
       "AMT_ANNUITY              NaN           NaN               NaN         NaN   \n",
       "\n",
       "                  AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  \\\n",
       "SK_ID_CURR          -0.012384        -0.010320                   -0.001071   \n",
       "CNT_CHILDREN         0.006415        -0.087053                   -0.180259   \n",
       "AMT_INCOME_TOTAL     0.414387         0.348522                    0.371289   \n",
       "AMT_CREDIT           0.928168         0.998997                    0.332148   \n",
       "AMT_ANNUITY               NaN         0.930591                    0.381766   \n",
       "\n",
       "                  DAYS_BIRTH_x  DAYS_EMPLOYED  DAYS_REGISTRATION  ...  \\\n",
       "SK_ID_CURR           -0.008336      -0.001024          -0.009581  ...   \n",
       "CNT_CHILDREN          0.739330       0.433684           0.673977  ...   \n",
       "AMT_INCOME_TOTAL      0.081557      -0.025511           0.113180  ...   \n",
       "AMT_CREDIT           -0.204316      -0.301116          -0.133019  ...   \n",
       "AMT_ANNUITY          -0.081644      -0.206107          -0.027237  ...   \n",
       "\n",
       "                  STATUS_0_MEAN  STATUS_1_MEAN  STATUS_2_MEAN  STATUS_3_MEAN  \\\n",
       "SK_ID_CURR             0.003357      -0.001850      -0.010326      -0.013329   \n",
       "CNT_CHILDREN           0.184563       0.197814       0.022270       0.017723   \n",
       "AMT_INCOME_TOTAL      -0.014646      -0.018543      -0.034895      -0.047507   \n",
       "AMT_CREDIT            -0.188297      -0.201939      -0.062915      -0.068763   \n",
       "AMT_ANNUITY           -0.176470      -0.156915      -0.059184      -0.065268   \n",
       "\n",
       "                  STATUS_4_MEAN  STATUS_5_MEAN  STATUS_C_MEAN  STATUS_X_MEAN  \\\n",
       "SK_ID_CURR            -0.015889      -0.017766      -0.000335      -0.001882   \n",
       "CNT_CHILDREN           0.021650       0.016981      -0.172132      -0.017152   \n",
       "AMT_INCOME_TOTAL      -0.047860      -0.027140      -0.033076       0.098954   \n",
       "AMT_CREDIT            -0.066161      -0.041964       0.155460       0.062682   \n",
       "AMT_ANNUITY           -0.063570      -0.040668       0.146155       0.052523   \n",
       "\n",
       "                  STATUS_nan_MEAN  PREVIOUS_LOAN_COUNTS  \n",
       "SK_ID_CURR                    NaN              0.001789  \n",
       "CNT_CHILDREN                  NaN             -0.011579  \n",
       "AMT_INCOME_TOTAL              NaN              0.153967  \n",
       "AMT_CREDIT                    NaN              0.132703  \n",
       "AMT_ANNUITY                   NaN              0.113175  \n",
       "\n",
       "[5 rows x 361 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = app_train.corr()\n",
    "\n",
    "upper = correlation.corr().where(np.triu(np.ones(correlation.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b31b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT_W_CITY', 'LIVE_REGION_NOT_WORK_REGION', 'LIVE_CITY_NOT_WORK_CITY', 'BASEMENTAREA_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_EMPLOYED_ANOM', 'NAME_INCOME_TYPE_Pensioner', 'OCCUPATION_TYPE_nan', 'ORGANIZATION_TYPE_XNA', 'HOUSETYPE_MODE_nan', 'WALLSMATERIAL_MODE_nan', 'EMERGENCYSTATE_MODE_No', 'EMERGENCYSTATE_MODE_nan', 'EXT_SOURCE_1_y', 'EXT_SOURCE_2_y', 'EXT_SOURCE_3_y', 'DAYS_BIRTH_y', 'EXT_SOURCE_1^2', 'EXT_SOURCE_1 EXT_SOURCE_2', 'EXT_SOURCE_1 EXT_SOURCE_3', 'EXT_SOURCE_1 DAYS_BIRTH', 'EXT_SOURCE_2^2', 'EXT_SOURCE_3^2', 'DAYS_BIRTH^2', 'EXT_SOURCE_1^3', 'EXT_SOURCE_1^2 EXT_SOURCE_2', 'EXT_SOURCE_1^2 EXT_SOURCE_3', 'EXT_SOURCE_1^2 DAYS_BIRTH', 'EXT_SOURCE_1 EXT_SOURCE_2^2', 'EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3', 'EXT_SOURCE_1 EXT_SOURCE_2 DAYS_BIRTH', 'EXT_SOURCE_1 EXT_SOURCE_3^2', 'EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH', 'EXT_SOURCE_1 DAYS_BIRTH^2', 'EXT_SOURCE_2^3', 'EXT_SOURCE_2^2 EXT_SOURCE_3', 'EXT_SOURCE_2^2 DAYS_BIRTH', 'EXT_SOURCE_2 EXT_SOURCE_3^2', 'EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH', 'EXT_SOURCE_2 DAYS_BIRTH^2', 'EXT_SOURCE_3^3', 'EXT_SOURCE_3^2 DAYS_BIRTH', 'EXT_SOURCE_3 DAYS_BIRTH^2', 'DAYS_BIRTH^3', 'ANNUITY_INCOME_PERCENT', 'DAYS_CREDIT_MEAN', 'DAYS_CREDIT_UPDATE_MEAN', 'CREDIT_DAY_OVERDUE_MEAN', 'AMT_CREDIT_SUM_MEAN', 'AMT_CREDIT_SUM_DEBT_MAX', 'AMT_CREDIT_SUM_DEBT_MEAN', 'AMT_ANNUITY_MEAN', 'MONTHS_BALANCE_MIN', 'CREDIT_ACTIVE_Active_MEAN', 'STATUS_4_MEAN']\n",
      "\n",
      "terdapat 95 feature yang saling berkorelasi\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "print(to_drop)\n",
    "print()\n",
    "print(f\"terdapat {len(to_drop)} feature yang saling berkorelasi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dba001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 266)\n",
      "Testing shape:  (48744, 265)\n"
     ]
    }
   ],
   "source": [
    "train = app_train.drop(columns = to_drop)\n",
    "test = app_test.drop(columns = to_drop)\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42750c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.to_csv('train_deletefeaute.csv')\n",
    "app_test.to_csv('test_deletefeaute.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da2fd1",
   "metadata": {},
   "source": [
    "## Bayesian Optimization for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a52a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93edfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_deletefeaute.csv')\n",
    "test = pd.read_csv('test_deletefeaute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac0b890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=1000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction,  max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "        params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':100, 'metric':'auc'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 8.99),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50),\n",
    "                                            }, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a6d5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-186b25d2c7ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mopt_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'opt_params' is not defined"
     ]
    }
   ],
   "source": [
    "del opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f2c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_sp... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.628511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.493919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.518360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.9098  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 3.014   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 6.69    \u001b[0m | \u001b[0m 34.07   \u001b[0m | \u001b[0m 0.04432 \u001b[0m | \u001b[0m 42.73   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7626  \u001b[0m | \u001b[0m 0.9927  \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 3.959   \u001b[0m | \u001b[0m 1.587   \u001b[0m | \u001b[0m 7.266   \u001b[0m | \u001b[0m 46.65   \u001b[0m | \u001b[0m 0.008033\u001b[0m | \u001b[0m 25.83   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.441239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.176063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7656  \u001b[0m | \u001b[95m 0.804   \u001b[0m | \u001b[95m 0.7661  \u001b[0m | \u001b[95m 3.891   \u001b[0m | \u001b[95m 2.61    \u001b[0m | \u001b[95m 8.905   \u001b[0m | \u001b[95m 40.96   \u001b[0m | \u001b[95m 0.04669 \u001b[0m | \u001b[95m 40.39   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.408783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.356561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.409485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 7.082   \u001b[0m | \u001b[0m 23.66   \u001b[0m | \u001b[0m 0.02719 \u001b[0m | \u001b[0m 40.26   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.5547  \u001b[0m | \u001b[0m 0.09395 \u001b[0m | \u001b[0m 1.853   \u001b[0m | \u001b[0m 7.442   \u001b[0m | \u001b[0m 32.76   \u001b[0m | \u001b[0m 0.09443 \u001b[0m | \u001b[0m 38.32   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.9559  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 3.133   \u001b[0m | \u001b[0m 2.317   \u001b[0m | \u001b[0m 7.502   \u001b[0m | \u001b[0m 45.8    \u001b[0m | \u001b[0m 0.03468 \u001b[0m | \u001b[0m 43.56   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 41.66   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 38.75   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.353263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.8729  \u001b[0m | \u001b[0m 0.5144  \u001b[0m | \u001b[0m 3.165   \u001b[0m | \u001b[0m 1.62    \u001b[0m | \u001b[0m 8.711   \u001b[0m | \u001b[0m 39.32   \u001b[0m | \u001b[0m 0.03409 \u001b[0m | \u001b[0m 27.24   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 0.9212  \u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 3.659   \u001b[0m | \u001b[0m 2.989   \u001b[0m | \u001b[0m 6.279   \u001b[0m | \u001b[0m 33.83   \u001b[0m | \u001b[0m 0.02548 \u001b[0m | \u001b[0m 30.52   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.2053  \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.203   \u001b[0m | \u001b[0m 8.891   \u001b[0m | \u001b[0m 41.4    \u001b[0m | \u001b[0m 0.06127 \u001b[0m | \u001b[0m 25.83   \u001b[0m |\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.265490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 0.4481  \u001b[0m | \u001b[0m 1.993   \u001b[0m | \u001b[0m 1.737   \u001b[0m | \u001b[0m 7.396   \u001b[0m | \u001b[0m 22.67   \u001b[0m | \u001b[0m 0.03566 \u001b[0m | \u001b[0m 42.06   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.370461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.311659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.8229  \u001b[0m | \u001b[0m 2.52    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 39.86   \u001b[0m | \u001b[0m 0.05694 \u001b[0m | \u001b[0m 40.77   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.275157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.289585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.928   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 42.45   \u001b[0m | \u001b[0m 0.003149\u001b[0m | \u001b[0m 42.85   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.402186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 0.9136  \u001b[0m | \u001b[0m 0.2606  \u001b[0m | \u001b[0m 0.8133  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 8.876   \u001b[0m | \u001b[0m 44.72   \u001b[0m | \u001b[0m 0.02918 \u001b[0m | \u001b[0m 40.03   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:527: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:532: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188457\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205007, number of used features: 345\n",
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 345\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432484\n",
      "[LightGBM] [Info] Start training from score -2.432484\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.9192  \u001b[0m | \u001b[0m 0.2468  \u001b[0m | \u001b[0m 2.645   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 8.847   \u001b[0m | \u001b[0m 39.15   \u001b[0m | \u001b[0m 0.04479 \u001b[0m | \u001b[0m 44.88   \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "X = train.drop('TARGET', axis=1)\n",
    "y = train['TARGET']\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6, n_estimators=100, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04338ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.7655963032907338, 'params': {'bagging_fraction': 0.8040436794880652, 'feature_fraction': 0.7660958764383504, 'lambda_l1': 3.8907837547492523, 'lambda_l2': 2.6100364447404574, 'max_depth': 8.904687185508728, 'min_child_weight': 40.96213538975256, 'min_split_gain': 0.04668645686304026, 'num_leaves': 40.39111270201556}}\n"
     ]
    }
   ],
   "source": [
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe84f4",
   "metadata": {},
   "source": [
    "# Build Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03a1e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "\n",
    "\n",
    "def train_model(features, test_features, n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "   \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    #optimal threshold\n",
    "    optimal_proba_cutoff = []\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for i, (train_indices, valid_indices) in enumerate(k_fold.split(features)):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(\n",
    "                    nthread=4,\n",
    "                    n_estimators=100, \n",
    "                    learning_rate=0.05,\n",
    "                    bagging_fraction= 0.8040436794880652, \n",
    "                    feature_fraction= 0.7660958764383504, \n",
    "                    lambda_l1= 3.8907837547492523, \n",
    "                    lambda_l2= 2.6100364447404574, \n",
    "                    max_depth= 9, \n",
    "                    min_child_weight= 40.96213538975256, \n",
    "                    min_split_gain= 0.04668645686304026, \n",
    "                    is_unbalance = True,\n",
    "                    num_leaves= 40)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'],\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "               \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "     \n",
    "        false_pos_rate, true_pos_rate, proba = roc_curve(valid_labels, out_of_fold[valid_indices])\n",
    "\n",
    "        optimal_proba_cutoff.append(sorted(list(zip(np.abs(true_pos_rate - false_pos_rate), proba)), key=lambda i: i[0], reverse=True)[0][1])\n",
    "        \n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "      \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores,\n",
    "                            }) \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9965c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 360)\n",
      "Testing Data Shape:  (48744, 360)\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660958764383504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660958764383504\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8907837547492523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8907837547492523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040436794880652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040436794880652\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6100364447404574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6100364447404574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's auc: 0.800546\ttrain's binary_logloss: 0.548492\tvalid's auc: 0.765424\tvalid's binary_logloss: 0.55664\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660958764383504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660958764383504\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8907837547492523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8907837547492523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040436794880652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040436794880652\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6100364447404574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6100364447404574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's auc: 0.800107\ttrain's binary_logloss: 0.548922\tvalid's auc: 0.766538\tvalid's binary_logloss: 0.557823\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660958764383504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660958764383504\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8907837547492523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8907837547492523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040436794880652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040436794880652\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6100364447404574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6100364447404574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's auc: 0.799196\ttrain's binary_logloss: 0.549944\tvalid's auc: 0.771015\tvalid's binary_logloss: 0.558259\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660958764383504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660958764383504\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8907837547492523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8907837547492523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040436794880652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040436794880652\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6100364447404574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6100364447404574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's auc: 0.799194\ttrain's binary_logloss: 0.549569\tvalid's auc: 0.767705\tvalid's binary_logloss: 0.556715\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660958764383504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660958764383504\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8907837547492523, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8907837547492523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8040436794880652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8040436794880652\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6100364447404574, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6100364447404574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's auc: 0.800057\ttrain's binary_logloss: 0.549019\tvalid's auc: 0.765226\tvalid's binary_logloss: 0.558969\n",
      "Baseline metrics\n",
      "      fold     train     valid\n",
      "0        0  0.800546  0.765424\n",
      "1        1  0.800107  0.766538\n",
      "2        2  0.799196  0.771015\n",
      "3        3  0.799194  0.767705\n",
      "4        4  0.800057  0.765226\n",
      "5  overall  0.799820  0.767172\n"
     ]
    }
   ],
   "source": [
    "metrics = train_model(features = train, test_features=test)\n",
    "print('Baseline metrics')\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
